---
title: "The Amplifier System of Australian English - Part 3"
author: "Anonymous"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---

This document shows an analysis of adjective amplification in Australian English based on the private dialogue section of ICE Australia. 

In a first step, the session is prepared by clearing the workspace, setting options, activating packages and functions, as well as loading relevant functions and the data.

```{r ampause_03_01, echo=T, eval = T, message=FALSE, warning=FALSE}
# clean current workspace
rm(list=ls(all=T))
# load libraries
library(dplyr)
library(ggplot2)
# set options
options(stringsAsFactors = F)
options(scipen = 999)
options(max.print=10000)
# define image directory
imageDirectory<-"images"
# load data
reallyaus <- read.table("datatables/ampaus05_statz.txt", sep = "\t", header = T)
# inspect data
str(reallyaus)
```

In a next step, we clean the data by removing data points not from private dialogues, renaming columns, and factorizing variables.

```{r ampause_03_03, echo=T, eval = T, message=FALSE, warning=FALSE}
# clean data
reallyaus <- reallyaus %>%
  dplyr::select(-Age) %>%
  dplyr::mutate(Gender = as.factor(Gender),
                Adjective = as.factor(Adjective),
                really = as.numeric(really),
                Age = AgeNumeric,
                AudienceSize = as.factor(AudienceSize),
                ConversationType = as.factor(ConversationType),
                Gender = as.factor(Gender),
                Priming = as.factor(Priming),
                Emotionality = as.factor(Emotionality),
                Function = as.factor(Function),
                SemanticCategory = as.factor(SemanticCategory),
                Gradability = as.numeric(Gradability),
                Occupation = as.factor(Occupation),
                FileSpeaker = as.factor(FileSpeaker),
                really = factor(really)) %>%
  dplyr::select(-AgeNumeric) %>%
  droplevels()
# only complete cases
reallyaus <- reallyaus[complete.cases(reallyaus),]
# inpsect data
str(reallyaus)
```

After cleaning the data, we check if we FileSpeaker can serve as a random effect.

```{r ampause_03_05, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot frequency of slots per speaker
hist(table(reallyaus$FileSpeaker), xlab = "Frequency of Adjectives per Speaker", 
     main = "", col = "lightgrey", breaks = 1:max(table(reallyaus$FileSpeaker)),
     ylim = c(0,100))
box()
```

The vast majority of speakers occur only once but given the high number of levels, FileSpeaker can be used as random effect! Next, we check if we need to remove variables due to data sparsity. We begin with SemanticCategory.

```{r ampause_03_07, echo=T, eval = T, message=FALSE, warning=FALSE}
table(reallyaus$SemanticCategory)
```


```{r ampause_03_09, echo=T, eval = T, message=FALSE, warning=FALSE}
table(reallyaus$Occupation)
```

We are now scaling frequency.

```{r ampause_03_13, echo=T, eval = T, message=FALSE, warning=FALSE}
reallyaus <- reallyaus %>%
  dplyr::mutate(Frequency = as.vector(scale(Frequency)))
# plot result
plot(reallyaus$Frequency, reallyaus$really)
abline(lm(reallyaus$really ~reallyaus$Frequency))
```

Now that the data is in order, we apply the Boruta variable selection procedure to identify variables that need to be tested in the regression modeling.


```{r ampause_03_15, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(Boruta)
# create dada for boruta
borutadata <- reallyaus
# run 1
set.seed(202003081)
boruta.ampaus <- Boruta(really~.,data=borutadata, maxRuns = 1000)
print(boruta.ampaus)
```


Next, we remove those variables that were confirmed as being non-important and perform a second Boruta run.

```{r ampause_03_17, echo=T, eval = T, message=FALSE, warning=FALSE}
# create vector of variables deemed not important
rejected <- names(boruta.ampaus$finalDecision)[which(boruta.ampaus$finalDecision == "Rejected")]
# update data for boruta
borutadata <- borutadata %>%
  dplyr::select(-rejected)
# run 2
set.seed(202003311)
boruta.ampaus <- Boruta(really~.,data=borutadata, maxRuns = 1000)
print(boruta.ampaus)
```

Next, we remove those variables that were confirmed as being non-important and perform a second Boruta run.

```{r ampause_03_19, echo=T, eval = T, message=FALSE, warning=FALSE}
# create vector of variables deemed not important
rejected <- names(boruta.ampaus$finalDecision)[which(boruta.ampaus$finalDecision != "Confirmed")]
# update data for boruta
borutadata <- borutadata %>%
  dplyr::select(-rejected)
# run 2
set.seed(202003312)
boruta.ampaus <- Boruta(really~.,data=borutadata, maxRuns = 1000)
print(boruta.ampaus)
```

Since no more variables are deemd unimportant, we now plot the results.

```{r ampause_03_21, echo=T, eval = T, message=FALSE, warning=FALSE}
plot(boruta.ampaus, cex = .75)
```

We now create a visualization of the results that is fit for publication.

```{r ampause_03_22, echo=T, eval = T, message=FALSE, warning=FALSE}
png("images/BorutaAmpAusE_publication.png",  width = 1500, height = 750)
par(mar = c(18, 8, 4, 2) + 0.1)
plot(boruta.ampaus, cex.axis=2, las=2, xlab="", ylab = "", cex = 2, 
     col = c(rep("grey50", 5), rep("grey90",3)))
abline(v = 3.5, lty = "dashed")
mtext("Predictors", 1, line = 16, at = 7, cex = 3)
mtext("Control", 1, line = 16, at = 2, cex = 3)
mtext("Importance", 2, line = 2.5, at = 5, cex = 3, las = 0)
dev.off()
plot(boruta.ampaus, cex.axis=2, las=2, xlab="", ylab = "", cex = 2, 
     col = c(rep("grey50", 5), rep("grey90",3)))
abline(v = 3.5, lty = "dashed")
mtext("Predictors", 1, line = 16, at = 7, cex = 3)
mtext("Control", 1, line = 16, at = 2, cex = 3)
mtext("Importance", 2, line = 2.5, at = 5, cex = 3, las = 0)
par(mar = c(5, 4, 4, 2) + 0.1)
```

We can now turn to the regression modeling and start by loading packages, setting options, and creating base-line fixed-effects models.

```{r ampause_03_23, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(rms)
# set options
reallyaus <- as.data.frame(reallyaus)
options(contrasts  =c("contr.treatment", "contr.poly"))
reallyaus.dist <- datadist(reallyaus)
options(datadist = "reallyaus.dist")
# generate initial minimal regression model 
m0.glm = glm(really ~ 1, family = binomial, data = reallyaus)
# inspect results
summary(m0.glm)
```

Now, we create base-line mixed-effects models and check if including the random effect is permitted by comparing the aic from the glm to aics from the glmers models and which random-effect structure is best.

```{r ampause_03_25, echo=T, eval = T, message=FALSE, warning=FALSE}
# load packages
library(lme4)
library(car)
# create model with random effect structure
m0.glmer = glmer(really ~ (1|FileSpeaker), data = reallyaus, family = binomial)
# extract AICs
aic.glm <- AIC(logLik(m0.glm))
aic.glmer <- AIC(logLik(m0.glmer))
# inspect AICs
aic.glm; aic.glmer
```

The model with both FileSpeaker  as random effect performs best and we now check if including this random effect structure is warranted by determining if it leads to a significant reduction in variance using a model likelihood ratio test.

```{r ampause_03_27, echo=T, eval = T, message=FALSE, warning=FALSE}
# test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) 
```

We now start with the model fitting. We fit the model to find the "best" model, i.e. the minimal adequate model, and use a step-wise step up procedure. We also need to add "control = glmerControl(optimizer = "bobyqa")" because otherwise R fails to converge.

```{r ampause_03_29, echo=T, eval = T, message=FALSE, warning=FALSE}
# cerate optimized base-line model
m0.glmer <- glmer(really ~ 1 + (1|FileSpeaker), 
                  family = binomial, 
                  data = reallyaus, 
                  control=glmerControl(optimizer="bobyqa"))
# add Age
m1.glm <- update(m0.glm, .~.+Age)
m1.glmer <- update(m0.glmer, .~.+Age)
anova(m1.glmer, m0.glmer, test = "Chi")
Anova(m1.glmer, type = "III", test = "Chi")
```

As Age is significant and because including Age causes both a drop in AIC and BIC, we retain it in the model and proceed by adding Gender.

```{r ampause_03_31, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender
ifelse(min(ftable(reallyaus$Gender, reallyaus$really)) == 0, "not possible", "possible")
m2.glm <- update(m1.glm, .~.+ Gender)
vif(m2.glm)
m2.glmer <- update(m1.glmer, .~.+ Gender)
anova(m2.glmer, m1.glmer, test = "Chi") 
Anova(m2.glmer, type = "III", test = "Chi")
```

As Gender is significant and because its inclusion in the model causes a drop in both AIC and BIC, we retain it in the model and proceed by adding Frequency.

```{r ampause_03_33, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Frequency
m3.glm <- update(m2.glm, .~.+ Frequency)
vif(m3.glm)
m3.glmer <- update(m2.glmer, .~.+ Frequency)
anova(m3.glmer, m2.glmer, test = "Chi")
Anova(m3.glmer, type = "III", test = "Chi")
```

As Frequency is significant and because its inclusion in the model causes a drop in AIC and only a minor increase in BIC, we retain it in the model and proceed by adding Priming.

```{r ampause_03_35, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Priming
ifelse(min(ftable(reallyaus$Priming, reallyaus$really)) == 0, "not possible", "possible")
m4.glm <- update(m3.glm, .~.+ Priming)
vif(m4.glm)
m4.glmer <- update(m3.glmer, .~.+ Priming)
anova(m4.glmer, m3.glmer, test = "Chi") 
Anova(m4.glmer, type = "III", test = "Chi")
```

As ConversationType is only marginally significant, we do not retain it in the model and proceed by adding all possible two-way interactions. In a first step, we determine which two-way interactions are possible.

```{r ampause_03_39, echo=T, eval = T, message=FALSE, warning=FALSE}
# find all 2-way interactions
library(utils)
vars <- c("Age", "Gender", "Frequency", "Priming")
intac <- t(combn(vars, 2))
intac
```

We begin by adding the interaction between Age and Gender.

```{r ampause_03_41, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Gender
m5.glm <- update(m4.glm, .~.+ Age*Gender)
vif(m5.glm)
m5.glmer <- update(m4.glmer, .~.+ Age*Gender)
anova(m5.glmer, m4.glmer, test = "Chi") 
```

As the interaction between Age and Gender is not significant, we do not retain it in the model and continue by adding the interaction between Age and Frequency.

```{r ampause_03_43, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Frequency
m6.glm <- update(m4.glm, .~.+ Age*Frequency)
vif(m6.glm)
m6.glmer <- update(m4.glmer, .~.+ Age*Frequency)
anova(m6.glmer, m4.glmer, test = "Chi")
Anova(m6.glmer, type = "III", test = "Chi")
```

As including the interaction between Age and Frequency is only marginally significant, we do not retain it in the model and continue by adding the interaction between Age and Priming.

```{r ampause_03_45, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Priming
m7.glm <- update(m4.glm, .~.+ Age*Priming)
vif(m7.glm)
m7.glmer <- update(m4.glmer, .~.+ Age*Priming)
anova(m7.glmer, m4.glmer, test = "Chi")
```

As the interaction between Age and Priming is significant, we retain it in the model and continue by adding the interaction between Gender and Frequency.

```{r ampause_03_46, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Frequency
m8.glm <- update(m4.glm, .~.+ Gender*Frequency)
vif(m8.glm)
m8.glmer <- update(m4.glmer, .~.+ Gender*Frequency)
anova(m8.glmer, m4.glmer, test = "Chi") 
```

As the interaction between Gender and Frequency is not significant, we do not retain it in the model and continue by adding the interaction between Frequency and Gender and Priming.

```{r ampause_03_47, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Priming
m9.glm <- update(m4.glm, .~.+ Gender*Priming)
vif(m9.glm)
m9.glmer <- update(m4.glmer, .~.+ Gender*Priming)
anova(m9.glmer, m4.glmer, test = "Chi") 
```

As including the interaction between Gender and Priming is not significant, we do not retain it in the model and continue by adding the interaction between Frequency and Priming.

```{r ampause_03_49, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Frequency*Priming
m10.glm <- update(m4.glm, .~.+ Frequency*Priming)
vif(m10.glm)
m10.glmer <- update(m4.glmer, .~.+ Frequency*Priming)
anova(m10.glmer, m4.glmer, test = "Chi") 
```

As the interaction between Gender and ConversationType is not significant, we do not retain it in the model and continue by checking which possible three-way interactions could be included in the model.

```{r ampause_03_57, echo=T, eval = T, message=FALSE, warning=FALSE}
# find all 3-way interactions
intac <- t(combn(vars, 3))
intac
```

In a next step, we create these fixed-effect versions of these models.

```{r ampause_03_58, echo=T, eval = T, message=FALSE, warning=FALSE}
m11.glm <- update(m4.glm, .~.+ Age*Gender*Frequency)
m12.glm <- update(m4.glm, .~.+ Age*Gender*Priming)
m13.glm <- update(m4.glm, .~.+ Age*Frequency*Priming)
m14.glm <- update(m4.glm, .~.+ Gender*Frequency*Priming)
```

Now, we test if the vifs for these models is acceptible

```{r ampause_03_59, echo=T, eval = T, message=FALSE, warning=FALSE}
max(vif(m11.glm))
max(vif(m12.glm))
max(vif(m13.glm))
max(vif(m14.glm))
```

We now create mixed-effect versions of those models, for which the vifs were acceptible.

```{r ampause_03_61, echo=T, eval = T, message=FALSE, warning=FALSE}
m11.glmer <- update(m4.glmer, .~.+ Age*Gender*Frequency)
m12.glmer <- update(m4.glmer, .~.+ Age*Gender*Priming)
m13.glmer <- update(m4.glmer, .~.+ Age*Frequency*Priming)
m14.glmer <- update(m4.glmer, .~.+ Gender*Frequency*Priming)
```

We now test if the inclusion of any of these interactions is significant.

```{r ampause_03_63, echo=T, eval = T, message=FALSE, warning=FALSE}
anova(m11.glmer, m4.glmer, test = "Chi")
```

As including the interaction Age:Gender:Frequency is not significant, we do not retain it in the model and continue by adding the interaction Age:Gender:Priming.

```{r ampause_03_65, echo=T, eval = T, message=FALSE, warning=FALSE}
anova(m12.glmer, m4.glmer, test = "Chi")
```

As the interaction Age:Gender:Priming is not significant, we do not retain it in the model and proceed by including the interaction Age:Frequency:Priming.

```{r ampause_03_66, echo=T, eval = T, message=FALSE, warning=FALSE}
anova(m13.glmer, m4.glmer, test = "Chi") 
```

As the interaction Age:Frequency:Priming is not significant, we do not retain it in the model and proceed by including the interaction Gender:Frequency:Priming.

```{r ampause_03_66, echo=T, eval = T, message=FALSE, warning=FALSE}
anova(m14.glmer, m4.glmer, test = "Chi") 
```

As the interaction Gender:Frequency:Priming is not significant, we do not retain it in the model. We have arrived at our final minimal adequate model. We nor start summarizing this final minimal adequate model.

```{r ampause_03_74, echo=T, eval = T, message=FALSE, warning=FALSE}
# load function for regression table summary
source("D:\\R/meblr.summary.R")
# set up summary table
meblrm_ampaus <- meblrm.summary(m0.glm, m4.glm, m0.glmer, m4.glmer, reallyaus$really) 
# save results to disc
write.table(meblrm_ampaus, "datatables/meblrm_ampaus.txt", sep="\t")
# show summary table
meblrm_ampaus
```

```{r ampause_03_75, echo=T, eval = T, message=FALSE, warning=FALSE}
# load function
library(car)
meblrm_ampaus_Anova <- Anova(m4.glmer, type = "III", test = "Chi")
# save results to disc
write.table(meblrm_ampaus_Anova, "datatables/meblrm_ampaus_Anova.txt", sep="\t")
# show results
meblrm_ampaus_Anova
```

Now, we check the prediction accuracy.

```{r ampause_03_75, echo=T, eval = T, message=FALSE, warning=FALSE}
# load function
library(caret)
pacc <- reallyaus %>%
  dplyr::select(Gender, Age, really, Priming, Frequency)
pacc$Prediction <- predict(m4.glmer, reallyaus, type = "response")
pacc <- pacc %>%
  dplyr::mutate(Predicted = ifelse(Prediction < .5, 0, 1)) %>%
  dplyr::mutate(Predicted = factor(Predicted))
caret::confusionMatrix(pacc$really, pacc$Predicted)
```

We now extract the effects of the significant predictors.

```{r ampause_03_76, echo=T, eval = T, message=FALSE, warning=FALSE}
# calculate effects
effectage <- anova(m1.glmer, m0.glmer, test = "Chi")
effectgender <- anova(m2.glmer, m1.glmer, test = "Chi")
effectfrequency <- anova(m3.glmer, m2.glmer, test = "Chi")
effectpriming <- anova(m4.glmer, m3.glmer, test = "Chi")
# show effects
effectage; effectgender; effectfrequency; effectpriming
```

Next, we create a table summarizing the model fitting procedure.

```{r ampause_03_77, echo=T, eval = T, message=FALSE, warning=FALSE}
# use customized model comparison function
# create comparireallyns
m1.m0 <- anova(m1.glmer, m0.glmer, test = "Chi")
m2.m1 <- anova(m2.glmer, m1.glmer, test = "Chi") 
m3.m2 <- anova(m3.glmer, m2.glmer, test = "Chi")
m4.m3 <- anova(m4.glmer, m3.glmer, test = "Chi") 
m5.m4 <- anova(m5.glmer, m4.glmer, test = "Chi") 
m6.m4 <- anova(m6.glmer, m4.glmer, test = "Chi") 
m7.m4 <- anova(m7.glmer, m4.glmer, test = "Chi") 
m8.m4 <- anova(m8.glmer, m4.glmer, test = "Chi") 
m9.m4 <- anova(m9.glmer, m4.glmer, test = "Chi") 
m10.m4 <- anova(m10.glmer, m4.glmer, test = "Chi") 
m11.m4 <- anova(m11.glmer, m4.glmer, test = "Chi") 
m12.m4 <- anova(m12.glmer, m4.glmer, test = "Chi") 
m13.m4 <- anova(m13.glmer, m4.glmer, test = "Chi") 
m14.m4 <- anova(m14.glmer, m4.glmer, test = "Chi") 
# create a list of the model comparireallyns
mdlcmp <- list(m1.m0, m2.m1, m3.m2, m4.m3, m5.m4, m6.m4, m7.m4, m8.m4, 
               m9.m4, m10.m4, m11.m4, m12.m4, m13.m4, m14.m4)
# load function
source("D:\\R/ModelFittingSummarySWSU.R") # for Mixed Effects Model fitting (step-wise step-up): Binary Logistic Mixed Effects Models
# apply function
mdl.cmp.glmersc.swsu.dm <- mdl.fttng.swsu(mdlcmp)
# save summary table
write.table(mdl.cmp.glmersc.swsu.dm, "datatables/mdl_cmp_glmersc_swsu_reallyaus.txt", sep="\t")
# inspect output
mdl.cmp.glmersc.swsu.dm
```

Next, we will visualize the effects.

```{r ampause_03_79, echo=T, eval = T, message=FALSE, warning=FALSE}
library(effects)
png("images/effectsfinalmodel.png",  width = 960, height = 480) 
plot(allEffects(m4.glmer), type="response", ylim=c(0,1), grid=TRUE, 
     lines = list(col="black",
                  lty = 1,
                  confint=list(style="bars",
                               col = "grey80")), 
     ylab = "Predicted probability of really")
dev.off()
plot(allEffects(m4.glmer), type="response", ylim=c(0,1), grid=TRUE, 
     lines = list(col="black",
                  lty = 1,
                  confint=list(style="bars",
                               col = "grey80")), 
     ylab = "Predicted probability of really")
```

Next, we create visualizations of the effects that are fit for publication.

```{r ampause_03_81, echo=T, eval = T, message=FALSE, warning=FALSE}
# predict probs of really
reallyaus$Prediction <- predict(m4.glmer, reallyaus, type="response")
# start plotting
p1 <- ggplot(reallyaus, aes(Gender, Prediction)) +
  geom_point(aes(x = Gender, y = Prediction), size = NA) +
  stat_summary(fun.y = mean, geom = "point", size = .5) +
  stat_summary(fun.y = mean, geom = "line") +
  stat_summary(fun.data = mean_cl_boot, geom = "errorbar", 
               width = 0.2, size = 1) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_light(base_size = 15)) +
  theme(legend.position="none", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.text.x = element_text(size=15)) +
  labs(x = "Gender", y = "Predicted probability of really") +
  scale_color_manual(values = c("grey30")) +
  ggsave(file = paste(imageDirectory,"PredReallyGender.png",sep="/"), 
       height = 4,  width = 4, dpi = 320)
# show plot
p1
```


```{r ampause_03_83, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
p2 <- ggplot(reallyaus, aes(x = Frequency, y = Prediction)) +
  geom_smooth(method = "lm", se = T, color = "gray30") +
  theme_set(theme_light(base_size = 15)) +
  theme(legend.position="none", 
        axis.text.x = element_text(size=15),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  coord_cartesian(ylim = c(0, 1)) +
  labs(y = "Predicted probability of really") +
  scale_x_continuous(name = "Logged and scaled frequency of adj. type",
                     breaks = seq(-1, 2, .5),
                     labels = seq(-1, 2, .5)) +
  guides(size = FALSE)+
  guides(alpha = FALSE) +
  ggsave(file = paste(imageDirectory,"PredReallyFrequency.png",
                      sep="/"), height = 4,  width = 6, dpi = 320)
p2
```

```{r ampause_03_85, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
#p3 <- ggplot(reallyaus, aes(x = reorder(Age, desc(Age)), y = Prediction)) +
p3 <- ggplot(reallyaus, aes(x = Age, y = Prediction)) +
  geom_smooth(aes(y = Prediction, x = Age), 
              colour="black", size=1, se = T, method = "lm") +
  theme_set(theme_light(base_size = 15)) +
  theme(legend.position="none", 
        axis.text.x = element_text(size=15),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  coord_cartesian(ylim = c(0, 1)) +
  labs(y = "Predicted probability of really",
       x = "Age") +
  scale_x_reverse() +
#  scale_x_continuous(name = "Age",
#                     breaks = rev(seq(10, 80, 10)),
#                     labels=rev(seq(10, 80, 10))) +
  guides(size = FALSE)+
  guides(alpha = FALSE) +
  ggsave(file = paste(imageDirectory,"PredReallyAge.png",
                      sep="/"), height = 4,  width = 6, dpi = 320)
p3
```


```{r ampause_03_89, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
p4 <- ggplot(reallyaus, aes(Priming, Prediction)) +
  geom_point(aes(x = Priming, y = Prediction), size = NA) +
  stat_summary(fun.y = mean, geom = "point", size = .5) +
  stat_summary(fun.y = mean, geom = "line") +
  stat_summary(fun.data = mean_cl_boot, geom = "errorbar", 
               width = 0.2, size = 1) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_light(base_size = 15)) +
  theme(legend.position="none", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.text.x = element_text(size=15)) +
  labs(x = "Priming", y = "Predicted probability of really") +
  scale_color_manual(values = c("grey30")) +
  ggsave(file = paste(imageDirectory,"PredReallyPriming.png",sep="/"), 
       height = 4,  width = 4, dpi = 320)
# show plot
p4
```


```{r ampause_03_91, echo=T, eval = T, message=FALSE, warning=FALSE}
randomtb <- ranef(m4.glmer)$FileSpeaker
rndmlngtb <- data.frame(rownames(randomtb), randomtb)
colnames(rndmlngtb) <- c("FileSpeaker", "Intercept")
rndmlngtb <- rndmlngtb[order(rndmlngtb$Intercept, decreasing = T),]

p5 <- ggplot(rndmlngtb, aes(FileSpeaker, Intercept)) +
  geom_point(aes(reorder(FileSpeaker, -Intercept, fun = Intercept), y=Intercept)) +
  coord_cartesian(ylim = c(-1, 1)) +
  theme_set(theme_bw(base_size = 15)) +
  theme(legend.position="none",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.text.x = element_blank()) +
  labs(x = "Speaker", y = "Adjustment to Intercept") +
  ggsave(file = paste(imageDirectory,"RanAdjective.png",sep="/"), 
       height = 5,  width = 7,  dpi = 320)
# show plot
p5
```

We will now perform a power analysis to check if the sample size was sufficient to arrive at robust conclusions.

We will now check if the sample size is sufficient to detect the weakest medium effect (Cohen's d 0.5) - the traditional scale is 0.2 for a small, 0.5 for medium sized, and 0.8 for a large or strong effect. In order to check what the weakest medium effect is, we need to determine the odds ratios of the fixed effects and then convert them into Cohen's d values for which we have associations between traditional denominations (small, medium, and large) and effect sife values. According to @chen2010big odds ratios of 1.68, 3.47, and 6.71 are equivalent to Cohen's d = 0.2 (small), 0.5 (medium), and 0.8 (large).

```{r ampause_03_93, echo=T, eval = T, message=FALSE, warning=FALSE}
estimatesfixedeffects <- fixef(m4.glmer)
exp(estimatesfixedeffects)
```

All effects are in the small range. We now manually set them to have an Estimate of 1.245 which is an equivalent to the weakest medium effect size.

```{r ampause_03_94, echo=T, eval = T, message=FALSE, warning=FALSE}
reallyaus <- reallyaus %>%
  dplyr::mutate(Age = as.vector(scale(Age)))
# load package
library(simr)
m4effects <- m4.glmer
fixef(m4effects)["Age"] <- 1.245
fixef(m4effects)["GenderWoman"] <- 1.245
fixef(m4effects)["Frequency"] <- 1.245
fixef(m4effects)["PrimingPrimed"] <- 1.245
estimatesfixedeffects <- fixef(m4effects)
exp(estimatesfixedeffects)
```

The effects now all correspond to an OR of 3.47 which corresponds to the weakest medium effect size for Cohen's d (.5 = OR 3.47).

We now manually set the effects to the weakest medium size for the actual models during model fitting and check if the smaple size is sufficient to detect this effect with at least 80 percent accuracy. We start with Age.

```{r ampause_03_95, echo=T, eval = T, message=FALSE, warning=FALSE}
m1p <- m1.glmer
fixef(m1p)["Age"] <- 1.245
pAge <- powerSim(m1p, fixed("Age", "z"), nsim=100, seed = 202004016)
# inspect results
pAge
# check errors
#lastResult()$errors
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency. We continue by checking the pwoer of the sample to detect the weakest medium effect for Gender.

```{r ampause_03_97, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m2p <- m2.glmer
fixef(m2p)["GenderWoman"] <- 1.245
pGender <- powerSim(m2p, fixed("Gender", "lr"), nsim=100)
# inspect results
pGender
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Gradability. We continue by checking the pwoer of the sample to detect the weakest medium effect for Age. We start with age group 26-40.

```{r ampause_03_99, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m3p <- m3.glmer
fixef(m3p)["Frequency"] <- 1.245
pFrequency <- powerSim(m3p, fixed("Frequency", "lr"), nsim=100)
# inspect results
pFrequency
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for age.

We continue by checking the power of the sample to detect the weakest medium effect for ConversationType.

```{r ampause_03_103, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m4p <- m4.glmer
fixef(m4p)["PrimingPrimed"] <- 1.245
pPriming <- powerSim(m4p, fixed("Priming", "lr"), nsim=100)
# inspect results
pPriming
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Priming. We continue by checking the pwoer of the sample to detect the weakest medium effect for Age:Gender.

```{r ampause_03_105, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003317)
m5p <- m5.glmer
fixef(m5p)["Age:GenderWoman"] <- 1.245
pAgeGender <- powerSim(m5p, fixed("Age:Gender", "lr"), nsim=100)
# inspect results
pAgeGender
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Age:Gradability. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Age2640.

```{r ampause_03_107, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m6p <- m6.glmer
fixef(m6p)["Age:Frequency"] <- 1.245
pAgeFrequency <- powerSim(m6p, fixed("Age:Frequency", "lr"), nsim=100)
# inspect results
pAgeFrequency
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Age:Frequency. We continue by checking the power of the sample to detect the weakest medium effect for Age:Priming.

```{r ampause_03_109, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m7p <- m7.glmer
fixef(m7p)["Age:PrimingPrimed"] <- 1.245
pAgePriming <- powerSim(m7p, fixed("Age:Priming", "lr"), nsim=100)
# inspect results
pAgePriming
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Age:Priming. We continue by checking the pwoer of the sample to detect the weakest medium effect for Gender:Frequency.

```{r ampause_03_111, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m8p <- m8.glmer
fixef(m8p)["GenderWoman:Frequency"] <- 1.245
pGenderFrequency <- powerSim(m8p, fixed("Gender:Frequency", "lr"), nsim=100)
# inspect results
pGenderFrequency
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Gender:Frequency. We continue by checking the pwoer of the sample to detect the weakest medium effect for Gender:Age.

```{r ampause_03_113, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m9p <- m9.glmer
fixef(m9p)["GenderWoman:PrimingPrimed"] <- 1.245
pGenderPriming <- powerSim(m9p, fixed("Gender:Priming", "lr"), nsim=100)
# inspect results
pGenderPriming
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Gender:Priming. We continue by checking the power of the sample to detect the weakest medium effect for Frequency:Priming.

```{r ampause_03_117, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m10p <- m10.glmer
fixef(m10p)["Frequency:PrimingPrimed"] <- 1.245
pFrequencyPriming <- powerSim(m10p, fixed("Frequency:Priming", "lr"), nsim=100)
# inspect results
pFrequencyPriming
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:Priming. We continue by checking the pwoer of the sample to detect the weakest medium effect for Age:Gender:Priming.

```{r ampause_03_119, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m11p <- m11.glmer
fixef(m11p)["Age:GenderWoman:Frequency"] <- 1.245
pAgeGenderFrequency <- powerSim(m11p, fixed("Age:Gender:Frequency", "lr"), nsim=100)
# inspect results
pAgeGenderFrequency
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Age:Gender:Frequency. We continue by checking the pwoer of the sample to detect the weakest medium effect for Age:Gender:Priming.

```{r ampause_03_121, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m12p <- m12.glmer
fixef(m12p)["Age:GenderWoman:PrimingPrimed"] <- 1.245
pAgeGenderPriming <- powerSim(m12p, fixed("Age:Gender:Priming", "lr"), nsim=100)
# inspect results
pAgeGenderPriming
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Age:Gender:Priming. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Gender:Age2640.

```{r ampause_03_123, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m13p <- m13.glmer
fixef(m13p)["Age:Frequency:PrimingPrimed"] <- 1.245
pAgeFrequencyPriming <- powerSim(m13p, fixed("Age:Frequency:Priming", "lr"), nsim=100)
# inspect results
pAgeFrequencyPriming
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:GenderWoman:Age26-40. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Gender:Age41-80.

```{r ampause_03_125, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m14p <- m14.glmer
fixef(m14p)["GenderWoman:Frequency:PrimingPrimed"] <- 1.245
pGenderFrequencyPriming <- powerSim(m14p, fixed("Gender:Frequency:Priming", "lr"), nsim=100)
# inspect results
pGenderFrequencyPriming
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Gender:Frequency:Priming. We have reached the end of part 3 of the analysis.
