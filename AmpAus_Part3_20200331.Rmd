---
title: "The Amplifier System of Australian English - Part 3"
author: "Anonymous"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---

This document shows an analysis of adjective amplification in Australian English based on the private dialogue section of ICE Australia. 

In a first step, the session is prepared by clearing the workspace, setting options, activating packages and functions, as well as loading relevant functions and the data.

```{r ampause_03_01, echo=T, eval = T, message=FALSE, warning=FALSE}
# clean current workspace
rm(list=ls(all=T))
# load libraries
library(dplyr)
library(ggplot2)
library(tidyr)
# set options
options(stringsAsFactors = F)
options(scipen = 999)
options(max.print=10000)
# define image directory
imageDirectory<-"images"
# load data
reallyaus <- read.table("datatables/ampaus05_statz.txt", sep = "\t", header = T)
# inspect data
str(reallyaus)
```

In a next step, we clean the data by removing data points not from private dialogues, renaming columns, and factorizing variables.

```{r ampause_03_03, echo=T, eval = T, message=FALSE, warning=FALSE}
# clean data
reallyaus <- reallyaus %>%
  dplyr::mutate(Gender = as.factor(Gender),
                Adjective = as.factor(Adjective),
                really = as.numeric(really),
                Age = as.factor(Age),
                AudienceSize = as.factor(AudienceSize),
                ConversationType = as.factor(ConversationType),
                Gender = as.factor(Gender),
                Priming = as.factor(Priming),
                Emotionality = as.factor(Emotionality),
                Function = as.factor(Function),
                SemanticCategory = as.factor(SemanticCategory),
                Gradability = as.numeric(Gradability),
                Occupation = as.factor(Occupation),
                FileSpeaker = as.factor(FileSpeaker),
                really = as.factor(really))
# only complete cases
reallyaus <- reallyaus[complete.cases(reallyaus),]
# inpsect data
str(reallyaus)
```

After cleaning the data, we check if we FileSpeaker can serve as a random effect.

```{r ampause_03_05, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot frequency of slots per speaker
hist(table(reallyaus$FileSpeaker), xlab = "Frequency of Adjectives per Speaker", 
     main = "", col = "lightgrey", breaks = 1:max(table(reallyaus$FileSpeaker)),
     ylim = c(0,100))
box()
```

The vast majority of speakers occur only once but given the high number of levels, FileSpeaker can be used as random effect! Next, we check if we need to remove variables due to data sparsity. We begin with SemanticCategory.

```{r ampause_03_07, echo=T, eval = T, message=FALSE, warning=FALSE}
table(reallyaus$SemanticCategory)
```


```{r ampause_03_09, echo=T, eval = T, message=FALSE, warning=FALSE}
table(reallyaus$Occupation)
```

We are now scaling frequency.

```{r ampause_03_13, echo=T, eval = T, message=FALSE, warning=FALSE}
reallyaus <- reallyaus %>%
  dplyr::mutate(Frequency = as.vector(scale(Frequency)))
# plot result
plot(reallyaus$Frequency, reallyaus$really)
abline(lm(reallyaus$really ~reallyaus$Frequency))
```

Now that the data is in order, we apply the Boruta variable selection procedure to identify variables that need to be tested in the regression modeling.


```{r ampause_03_15, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(Boruta)
# create dada for boruta
borutadata <- reallyaus
# run 1
set.seed(202003081)
boruta.ampaus <- Boruta(really~.,data=borutadata, maxRuns = 1000)
print(boruta.ampaus)
```


Next, we remove those variables that were confirmed as being non-important and perform a second Boruta run.

```{r ampause_03_17, echo=T, eval = T, message=FALSE, warning=FALSE}
# create vector of variables deemed not important
rejected <- names(boruta.ampaus$finalDecision)[which(boruta.ampaus$finalDecision == "Rejected")]
# update data for boruta
borutadata <- borutadata %>%
  dplyr::select(-rejected)
# run 2
set.seed(202003311)
boruta.ampaus <- Boruta(really~.,data=borutadata, maxRuns = 1000)
print(boruta.ampaus)
```

Next, we remove those variables that were confirmed as being non-important and perform a second Boruta run.

```{r ampause_03_19, echo=T, eval = T, message=FALSE, warning=FALSE}
# create vector of variables deemed not important
rejected <- names(boruta.ampaus$finalDecision)[which(boruta.ampaus$finalDecision == "Rejected")]
# update data for boruta
borutadata <- borutadata %>%
  dplyr::select(-rejected)
# run 2
set.seed(202003312)
boruta.ampaus <- Boruta(really~.,data=borutadata, maxRuns = 1000)
print(boruta.ampaus)
```

Since no more variables are deemd unimportant, we now plot the results.

```{r ampause_03_21, echo=T, eval = T, message=FALSE, warning=FALSE}
plot(boruta.ampaus, cex = .75)
```

We now create a visualization of the results that is fit for publication.

```{r ampause_03_22, echo=T, eval = T, message=FALSE, warning=FALSE}
png("images/BorutaAmpAusE_publication.png",  width = 1500, height = 750)
par(mar = c(18, 8, 4, 2) + 0.1)
plot(boruta.ampaus, cex.axis=2, las=2, xlab="", ylab = "", cex = 2, 
     col = c(rep("grey50", 6), rep("grey90",3)))
abline(v = 3.5, lty = "dashed")
mtext("Predictors", 1, line = 16, at = 7, cex = 3)
mtext("Control", 1, line = 16, at = 2, cex = 3)
mtext("Importance", 2, line = 2.5, at = 5, cex = 3, las = 0)
dev.off()
plot(boruta.ampaus, cex.axis=2, las=2, xlab="", ylab = "", cex = 2, 
     col = c(rep("grey50", 6), rep("grey90",3)))
abline(v = 3.5, lty = "dashed")
mtext("Predictors", 1, line = 16, at = 7, cex = 3)
mtext("Control", 1, line = 16, at = 2, cex = 3)
mtext("Importance", 2, line = 2.5, at = 5, cex = 3, las = 0)
par(mar = c(5, 4, 4, 2) + 0.1)
```

We can now turn to the regression modeling and start by loading packages, setting options, and creating base-line fixed-effects models.

```{r ampause_03_23, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(rms)
# set options
options(contrasts  =c("contr.treatment", "contr.poly"))
reallyaus.dist <- datadist(reallyaus)
options(datadist = "reallyaus.dist")
# generate initial minimal regression model 
m0.glm = glm(really ~ 1, family = binomial, data = reallyaus)
# inspect results
summary(m0.glm)
```

Now, we create base-line mixed-effects models and check if including the random effect is permitted by comparing the aic from the glm to aics from the glmers models and which random-effect structure is best.

```{r ampause_03_25, echo=T, eval = T, message=FALSE, warning=FALSE}
# load packages
library(lme4)
library(car)
# create model with random effect structure
m0.glmera = glmer(really ~ (1|FileSpeaker), data = reallyaus, family = binomial)
m0.glmerb = glmer(really ~ (1|Adjective), data = reallyaus, family = binomial)
m0.glmerc = glmer(really ~ (1|FileSpeaker) + (1|Adjective), data = reallyaus, family = binomial)
# extract AICs
aic.glm <- AIC(logLik(m0.glm))
aic.glmera <- AIC(logLik(m0.glmera))
aic.glmerb <- AIC(logLik(m0.glmerb))
aic.glmerc <- AIC(logLik(m0.glmerc))
# inspect AICs
aic.glm; aic.glmera; aic.glmerb; aic.glmerc 
```

The model with both FileSpeaker and Adjective as random effects performs best and we now check if including this random effect structure is warranted by determining if it leads to a significant reduction in variance using a model likelihood ratio test.

```{r ampause_03_27, echo=T, eval = T, message=FALSE, warning=FALSE}
# test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmerc)
pchisq(as.numeric(null.id), df=1, lower.tail=F) 
```

We now start with the model fitting. We fit the model to find the "best" model, i.e. the minimal adequate model, and use a step-wise step up procedure. We also need to add "control = glmerControl(optimizer = "bobyqa")" because otherwise R fails to converge.

```{r ampause_03_29, echo=T, eval = T, message=FALSE, warning=FALSE}
# cerate optimized base-line model
m0.glmer <- glmer(really ~ 1 + (1|FileSpeaker)+ (1|Adjective), 
                  family = binomial, 
                  data = reallyaus, 
                  control=glmerControl(optimizer="bobyqa"))
# add Frequency
m1.glm <- update(m0.glm, .~.+Frequency)
m1.glmer <- update(m0.glmer, .~.+Frequency)
anova(m1.glmer, m0.glmer, test = "Chi")
Anova(m1.glmer, type = "III", test = "Chi")
```

As Frequency is significant and because including Frequency causes both a drop in AIC and BIC, we retain it in the model and proceed by adding Gender.

```{r ampause_03_31, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender
m2.glm <- update(m1.glm, .~.+ Gender)
vif(m2.glm)
m2.glmer <- update(m1.glmer, .~.+ Gender)
anova(m2.glmer, m1.glmer, test = "Chi") 
Anova(m2.glmer, type = "III", test = "Chi")
```

As Gender is significant and because its inclusion in the model causes a drop in both AIC and BIC, we retain it in the model and proceed by adding Age.

```{r ampause_03_33, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age
ifelse(min(ftable(reallyaus$Age, reallyaus$really)) == 0, "not possible", "possible")
m3.glm <- update(m2.glm, .~.+ Age)
vif(m3.glm)
m3.glmer <- update(m2.glmer, .~.+ Age)
anova(m3.glmer, m2.glmer, test = "Chi")
Anova(m3.glmer, type = "III", test = "Chi")
```

As Age is significant and because its inclusion in the model causes a drop in AIC and only a minor increase in BIC, we retain it in the model and proceed by adding ConversationType.

```{r ampause_03_35, echo=T, eval = T, message=FALSE, warning=FALSE}
# add ConversationType
ifelse(min(ftable(reallyaus$ConversationType, reallyaus$really)) == 0, "not possible", "possible")
m4.glm <- update(m3.glm, .~.+ ConversationType)
vif(m4.glm)
m4.glmer <- update(m3.glmer, .~.+ ConversationType)
anova(m4.glmer, m3.glmer, test = "Chi") 
Anova(m4.glmer, type = "III", test = "Chi")
```

As ConversationType is only marginally significant, we do not retain it in the model and proceed by adding AudienceSize.

```{r ampause_03_36, echo=T, eval = T, message=FALSE, warning=FALSE}
# add AudienceSize
ifelse(min(ftable(reallyaus$AudienceSize, reallyaus$really)) == 0, "not possible", "possible")
m5.glm <- update(m3.glm, .~.+ AudienceSize)
vif(m5.glm)
m5.glmer <- update(m3.glmer, .~.+ AudienceSize)
anova(m5.glmer, m3.glmer, test = "Chi") 
```

As AudienceSize is not significant, we do not retain it in the model and proceed by adding all possible two-way interactions. In a first step, we determine which two-way interactions are possible.

```{r ampause_03_39, echo=T, eval = T, message=FALSE, warning=FALSE}
# find all 2-way interactions
library(utils)
vars <- c("Frequency", "Gender", "Age", "ConversationType", "AudienceSize")
intac <- t(combn(vars, 2))
intac
```

We begin by adding the interaction between Frequency and Gender.

```{r ampause_03_41, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Frequency*Gender
m6.glm <- update(m3.glm, .~.+ Frequency*Gender)
vif(m6.glm)
m6.glmer <- update(m3.glmer, .~.+ Frequency*Gender)
anova(m6.glmer, m3.glmer, test = "Chi") 
```

As the interaction between Frequency and Gender is not significant, we do not retain it in the model and continue by adding the interaction between Frequency and Age.

```{r ampause_03_43, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Frequency*Age
m7.glm <- update(m3.glm, .~.+ Frequency*Age)
vif(m7.glm)
m7.glmer <- update(m3.glmer, .~.+ Frequency*Age)
anova(m7.glmer, m3.glmer, test = "Chi") 
```

As including the interaction between Frequency and Age is not significant, we do not retain it in the model and continue by adding the interaction between Frequency and ConversationType.

```{r ampause_03_45, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Frequency*ConversationType
m8.glm <- update(m3.glm, .~.+ Frequency*ConversationType)
vif(m8.glm)
m8.glmer <- update(m3.glmer, .~.+ Frequency*ConversationType)
anova(m8.glmer, m3.glmer, test = "Chi")
Anova(m8.glmer, type = "III", test = "Chi")
```

As the interaction between Frequency and ConversationType is significant, we retain it in the model and continue by adding the interaction between Frequency and AudienceSize.

```{r ampause_03_46, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Frequency*AudienceSize
m9.glm <- update(m8.glm, .~.+ Frequency*AudienceSize)
vif(m9.glm)
m9.glmer <- update(m8.glmer, .~.+ Frequency*AudienceSize)
anova(m9.glmer, m8.glmer, test = "Chi") 
```

As the interaction between Frequency and AudienceSize is not significant, we do not retain it in the model and continue by adding the interaction between Frequency and Gender and Age.

```{r ampause_03_47, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Age
m10.glm <- update(m8.glm, .~.+ Gender*Age)
vif(m10.glm)
m10.glmer <- update(m8.glmer, .~.+ Gender*Age)
anova(m10.glmer, m8.glmer, test = "Chi") 
```

As including the interaction between Gender and Age is not significant, we do not retain it in the model and continue by adding the interaction between Gender and ConversationType.

```{r ampause_03_49, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*ConversationType
m11.glm <- update(m8.glm, .~.+ Gender*ConversationType)
vif(m11.glm)
m11.glmer <- update(m8.glmer, .~.+ Gender*ConversationType)
anova(m11.glmer, m8.glmer, test = "Chi") 
```

As the interaction between Gender and ConversationType is not significant, we do not retain it in the model and continue by adding the interaction between Gender and AudienceSize.

```{r ampause_03_49, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*AudienceSize
m12.glm <- update(m8.glm, .~.+ Gender*AudienceSize)
vif(m12.glm)
m12.glmer <- update(m8.glmer, .~.+ Gender*AudienceSize)
anova(m12.glmer, m8.glmer, test = "Chi") 
Anova(m12.glmer, type = "III", test = "Chi")
```

As the interaction between Gender and AudienceSize is not significant, we do not retain it in the model and continue by adding the interaction between Age and ConversationType.

```{r ampause_03_51, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*ConversationType
m13.glm <- update(m8.glm, .~.+ Age*ConversationType)
vif(m13.glm)
m13.glmer <- update(m8.glmer, .~.+ Age*ConversationType)
anova(m13.glmer, m8.glmer, test = "Chi") 
```

As the interaction between Age and ConversationType is not significant, we do not retain it in the model and continue by adding the interaction between Age and AudienceSize.

```{r ampause_03_51, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*AudienceSize
m14.glm <- update(m8.glm, .~.+ Age*AudienceSize)
vif(m14.glm)
m14.glmer <- update(m8.glmer, .~.+ Age*AudienceSize)
anova(m14.glmer, m8.glmer, test = "Chi") 
Anova(m14.glmer, type = "III", test = "Chi")
``` 

As the interaction between Age and AudienceSize is not significant, we do not retain it in the model and continue by checking which possible three-way interactions could be included in the model.

```{r ampause_03_57, echo=T, eval = T, message=FALSE, warning=FALSE}
# find all 3-way interactions
intac <- t(combn(vars, 3))
intac
```

In a next step, we create these fixed-effect versions of these models.

```{r ampause_03_58, echo=T, eval = T, message=FALSE, warning=FALSE}
m15.glm <- update(m8.glm, .~.+ Frequency*Gender*Age)
m16.glm <- update(m8.glm, .~.+ Frequency*Gender*ConversationType)
m17.glm <- update(m8.glm, .~.+ Frequency*Gender*AudienceSize)
m18.glm <- update(m8.glm, .~.+ Frequency*Age*ConversationType)
m19.glm <- update(m8.glm, .~.+ Frequency*Age*AudienceSize)
m20.glm <- update(m8.glm, .~.+ Frequency*ConversationType*AudienceSize)
m21.glm <- update(m8.glm, .~.+ Gender*Age*ConversationType)
m22.glm <- update(m8.glm, .~.+ Gender*Age*AudienceSize)
m23.glm <- update(m8.glm, .~.+ Gender*ConversationType*AudienceSize)
m24.glm <- update(m8.glm, .~.+ Age*ConversationType*AudienceSize)
```

Now, we test if the vifs for these models is acceptible

```{r ampause_03_59, echo=T, eval = T, message=FALSE, warning=FALSE}
max(vif(m15.glm))
max(vif(m16.glm))
max(vif(m17.glm))
max(vif(m18.glm))
max(vif(m19.glm))
max(vif(m20.glm))
max(vif(m21.glm)) # too high
max(vif(m22.glm)) # too high
max(vif(m23.glm))
max(vif(m24.glm))
```

We now create mixed-effect versions of those models, for which the vifs were acceptible.

```{r ampause_03_61, echo=T, eval = T, message=FALSE, warning=FALSE}
m15.glmer <- update(m8.glmer, .~.+ Frequency*Gender*Age)
m16.glmer <- update(m8.glmer, .~.+ Frequency*Gender*ConversationType)
m17.glmer <- update(m8.glmer, .~.+ Frequency*Gender*AudienceSize)
m18.glmer <- update(m8.glmer, .~.+ Frequency*Age*ConversationType)
m19.glmer <- update(m8.glmer, .~.+ Frequency*Age*AudienceSize)
m20.glmer <- update(m8.glmer, .~.+ Frequency*ConversationType*AudienceSize)
m23.glmer <- update(m8.glmer, .~.+ Gender*ConversationType*AudienceSize)
m24.glmer <- update(m8.glmer, .~.+ Age*ConversationType*AudienceSize)
```

We now test if the inclusion of any of these interactions is significant.

```{r ampause_03_63, echo=T, eval = T, message=FALSE, warning=FALSE}
anova(m15.glmer, m8.glmer, test = "Chi")
```

As including the interaction Frequency:Gender:Age is not significant, we do not retain it in the model and continue by adding the interaction Frequency:Gender:ConversationType.

```{r ampause_03_65, echo=T, eval = T, message=FALSE, warning=FALSE}
anova(m16.glmer, m8.glmer, test = "Chi")
```

As the interaction Frequency:Gender:ConversationType is not significant, we do not retain it in the model proceed by including the interaction Frequency:Age:ConversationType.

```{r ampause_03_66, echo=T, eval = T, message=FALSE, warning=FALSE}
anova(m17.glmer, m8.glmer, test = "Chi") 
```

As the interaction Frequency:Age:ConversationType is not significant, we do not retain it in the model. 






We have arrived at our final minimal adequate model. We nor start summarizing this final minimal adequate model.

```{r ampause_03_74, echo=T, eval = T, message=FALSE, warning=FALSE}
# load function for regression table summary
source("D:\\R/meblr.summary.tworandom.R")
# set up summary table
meblrm_ampaus <- meblrm.summary(m0.glm, m4.glm, m0.glmer, m4.glmer, reallyaus$really) 
# save results to disc
write.table(meblrm_ampaus, "datatables/meblrm_ampaus.txt", sep="\t")
# show summary table
meblrm_ampaus
```

```{r ampause_03_75, echo=T, eval = T, message=FALSE, warning=FALSE}
# load function
library(car)
meblrm_ampaus_Anova <- Anova(m4.glmer, type = "III", test = "Chi")
# save results to disc
write.table(meblrm_ampaus_Anova, "datatables/meblrm_ampaus_Anova.txt", sep="\t")
# show results
meblrm_ampaus_Anova
```

We now extract the effects of the significant predictors.

```{r ampause_03_76, echo=T, eval = T, message=FALSE, warning=FALSE}
# calculate effects
effectfrequency <- anova(m1.glmer, m0.glmer, test = "Chi")
effectgender <- anova(m2.glmer, m1.glmer, test = "Chi")
effectage <- anova(m3.glmer, m2.glmer, test = "Chi")
effectpriming <- anova(m4.glmer, m3.glmer, test = "Chi")
# show effects
effectfrequency; effectgender; effectage; effectpriming
```

Next, we create a table summarizing the model fitting procedure.

```{r ampause_03_77, echo=T, eval = T, message=FALSE, warning=FALSE}
# use customized model comparison function
# create comparireallyns
m1.m0 <- anova(m1.glmer, m0.glmer, test = "Chi")
m2.m1 <- anova(m2.glmer, m1.glmer, test = "Chi") 
m3.m2 <- anova(m3.glmer, m2.glmer, test = "Chi")
m4.m3 <- anova(m4.glmer, m3.glmer, test = "Chi") 
m5.m4 <- anova(m5.glmer, m4.glmer, test = "Chi") 
m6.m4 <- anova(m6.glmer, m4.glmer, test = "Chi") 
m7.m4 <- anova(m7.glmer, m4.glmer, test = "Chi") 
m8.m4 <- anova(m8.glmer, m4.glmer, test = "Chi") 
m9.m4 <- anova(m9.glmer, m4.glmer, test = "Chi") 
m10.m4 <- anova(m10.glmer, m4.glmer, test = "Chi") 
m11.m4 <- anova(m11.glmer, m4.glmer, test = "Chi") 
m12.m4 <- anova(m12.glmer, m4.glmer, test = "Chi") 
m13.m4 <- anova(m13.glmer, m4.glmer, test = "Chi") 
# create a list of the model comparireallyns
mdlcmp <- list(m1.m0, m2.m1, m3.m2, m4.m3, m5.m4, m6.m4, m7.m4, m8.m4, 
               m9.m4, m10.m4, m11.m4, m12.m4, m13.m4)
# load function
source("D:\\R/ModelFittingSummarySWSU.R") # for Mixed Effects Model fitting (step-wise step-up): Binary Logistic Mixed Effects Models
# apply function
mdl.cmp.glmersc.swsu.dm <- mdl.fttng.swsu(mdlcmp)
# save summary table
write.table(mdl.cmp.glmersc.swsu.dm, "mdl_cmp_glmersc_swsu_reallyaus.txt", sep="\t")
# inspect output
mdl.cmp.glmersc.swsu.dm
```

Next, we will visualize the effects.

```{r ampause_03_79, echo=T, eval = T, message=FALSE, warning=FALSE}
library(effects)
png("images/effectsfinalmodel.png",  width = 960, height = 480) 
plot(allEffects(m4.glmer), type="response", ylim=c(0,1), grid=TRUE, 
     lines = list(col="black",
                  lty = 1,
                  confint=list(style="bars",
                               col = "grey80")), 
     ylab = "Predicted probability of really")
dev.off()
plot(allEffects(m4.glmer), type="response", ylim=c(0,1), grid=TRUE, 
     lines = list(col="black",
                  lty = 1,
                  confint=list(style="bars",
                               col = "grey80")), 
     ylab = "Predicted probability of really")
```

Next, we create visualizations of the effects that are fit for publication.

```{r ampause_03_81, echo=T, eval = T, message=FALSE, warning=FALSE}
# predict probs of really
reallyaus$Prediction <- predict(m4.glmer, reallyaus, type="response")
# start plotting
p1 <- ggplot(reallyaus, aes(Gender, Prediction)) +
  geom_point(aes(x = Gender, y = Prediction), size = NA) +
  stat_summary(fun.y = mean, geom = "point", size = .5) +
  stat_summary(fun.y = mean, geom = "line") +
  stat_summary(fun.data = mean_cl_boot, geom = "errorbar", 
               width = 0.2, size = 1) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_light(base_size = 15)) +
  theme(legend.position="none", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.text.x = element_text(size=15)) +
  labs(x = "Gender", y = "Predicted probability of really") +
  scale_color_manual(values = c("grey30")) +
  ggsave(file = paste(imageDirectory,"PredReallyGender.png",sep="/"), 
       height = 5,  width = 5, dpi = 320)
# show plot
p1
```


```{r ampause_03_83, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
p2 <- ggplot(reallyaus, aes(x = Frequency, y = Prediction)) +
  geom_smooth(method = "lm", se = T, color = "gray30") +
  theme_set(theme_light(base_size = 15)) +
  theme(legend.position="none", 
        axis.text.x = element_text(size=15),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  coord_cartesian(ylim = c(0, 1)) +
  labs(y = "Predicted probability of really") +
  scale_x_continuous(name = "Logged frequency of adj. type",
                     breaks = seq(-1, 2, .5),
                     labels = seq(-1, 2, .5)) +
  guides(size = FALSE)+
  guides(alpha = FALSE) +
  ggsave(file = paste(imageDirectory,"PredReallyFrequency.png",
                      sep="/"), height = 3,  width = 5, dpi = 320)
p2

```

```{r ampause_03_85, echo=T, eval = T, message=FALSE, warning=FALSE}
# prepare data
Agelbs <- names(table(reallyaus$Age))
pd3 <- reallyaus %>%
  dplyr::mutate(Age = ifelse(Age == "41-80", 1,
                             ifelse(Age == "26-40", 2, 3))) %>%
  dplyr::mutate(Age = as.numeric(Age))
# start plotting
p3a <- ggplot(pd3, aes(x = reorder(Age, desc(Age)), y = Prediction)) +
  geom_smooth(aes(y = Prediction, x = Age), 
              colour="black", size=1, se = T, method = "lm") +
  theme_set(theme_light(base_size = 15)) +
  theme(legend.position="none", 
        axis.text.x = element_text(size=15),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  coord_cartesian(ylim = c(0, 1)) +
  labs(y = "Predicted probability of really",
       x = "Age") +
    scale_x_continuous(name = "Age",
                     breaks = c(1, 2, 3),
                     labels=rev(Agelbs)) +
  guides(size = FALSE)+
  guides(alpha = FALSE) +
  ggsave(file = paste(imageDirectory,"PredReallyAge.png",
                      sep="/"), height = 3,  width = 5, dpi = 320)
p3a
```

```{r ampause_03_87, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
p3b <- ggplot(reallyaus, aes(Age, Prediction)) +
  geom_point(aes(x = Age, y = Prediction), size = NA) +
  stat_summary(fun.y = mean, geom = "point", size = .5) +
  stat_summary(fun.y = mean, geom = "line") +
  stat_summary(fun.data = mean_cl_boot, geom = "errorbar", 
               width = 0.2, size = 1) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_light(base_size = 15)) +
  theme(legend.position="none", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.text.x = element_text(size=15)) +
  labs(x = "Age", y = "Predicted probability of really") +
  scale_color_manual(values = c("grey30")) +
  ggsave(file = paste(imageDirectory,"PredReallyAgeCat.png",sep="/"), 
       height = 5,  width = 5, dpi = 320)
# show plot
p3b
```


```{r ampause_03_89, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
p4 <- ggplot(reallyaus, aes(ConversationType, Prediction)) +
  geom_point(aes(x = ConversationType, y = Prediction), size = NA) +
  stat_summary(fun.y = mean, geom = "point", size = .5) +
  stat_summary(fun.y = mean, geom = "line") +
  stat_summary(fun.data = mean_cl_boot, geom = "errorbar", 
               width = 0.2, size = 1) +
  coord_cartesian(ylim = c(0, 1)) +
  theme_set(theme_light(base_size = 15)) +
  theme(legend.position="none", 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.text.x = element_text(size=15)) +
  labs(x = "ConversationType", y = "Predicted probability of really") +
  scale_color_manual(values = c("grey30")) +
  ggsave(file = paste(imageDirectory,"PredReallyConversationType.png",sep="/"), 
       height = 5,  width = 5, dpi = 320)
# show plot
p4
```

```{r ampause_03_90, echo=T, eval = T, message=FALSE, warning=FALSE}
randomtb <- ranef(m4.glmer)$Adjective
rndmlngtb <- data.frame(rownames(randomtb), randomtb)
colnames(rndmlngtb) <- c("Adjective", "Intercept")
rndmlngtb <- rndmlngtb[order(rndmlngtb$Intercept, decreasing = T),]

p5 <- ggplot(rndmlngtb, aes(Adjective, Intercept)) +
  geom_point(aes(reorder(Adjective, -Intercept, fun = Intercept), y=Intercept)) +
  coord_cartesian(ylim = c(-.1, .1)) +
  theme_set(theme_bw(base_size = 15)) +
  theme(legend.position="none",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.text.x = element_text(size=5, angle=90)) +
  labs(x = "Adjective", y = "Adjustment to Intercept") +
  ggsave(file = paste(imageDirectory,"RanAdjective.png",sep="/"), 
       height = 5,  width = 7,  dpi = 320)
# show plot
p5
```

```{r ampause_03_91, echo=T, eval = T, message=FALSE, warning=FALSE}
randomtb <- ranef(m4.glmer)$FileSpeaker
rndmlngtb <- data.frame(rownames(randomtb), randomtb)
colnames(rndmlngtb) <- c("FileSpeaker", "Intercept")
rndmlngtb <- rndmlngtb[order(rndmlngtb$Intercept, decreasing = T),]

p6 <- ggplot(rndmlngtb, aes(FileSpeaker, Intercept)) +
  geom_point(aes(reorder(FileSpeaker, -Intercept, fun = Intercept), y=Intercept)) +
  coord_cartesian(ylim = c(-1, 1)) +
  theme_set(theme_bw(base_size = 15)) +
  theme(legend.position="none",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        axis.text.x = element_blank()) +
  labs(x = "Speaker", y = "Adjustment to Intercept") +
  ggsave(file = paste(imageDirectory,"RanAdjective.png",sep="/"), 
       height = 5,  width = 7,  dpi = 320)
# show plot
p6
```

We will now perform a power analysis to check if the sample size was sufficient to arrive at robust conclusions.

We will now check if the sample size is sufficient to detect the weakest medium effect (Cohen's d 0.5) - the traditional scale is 0.2 for a small, 0.5 for medium sized, and 0.8 for a large or strong effect. In order to check what the weakest medium effect is, we need to determine the odds ratios of the fixed effects and then convert them into Cohen's d values for which we have associations between traditional denominations (small, medium, and large) and effect sife values. According to @chen2010big odds ratios of 1.68, 3.47, and 6.71 are equivalent to Cohen's d = 0.2 (small), 0.5 (medium), and 0.8 (large).

```{r ampause_03_93, echo=T, eval = T, message=FALSE, warning=FALSE}
estimatesfixedeffects <- fixef(m4.glmer)
exp(estimatesfixedeffects)
```

Both effects are in the small range. We now manually set the effects to the weakest medium size and check if the smaple size is sufficient to detect this effect with at least 80 percent accuracy. We start with Frequency.

```{r ampause_03_95, echo=T, eval = T, message=FALSE, warning=FALSE}
# load package
library(simr)
set.seed(202003206)
m1p <- m1.glmer
fixef(m1p)["Frequency"] <- 1.245
pFrequency <- powerSim(m1p, fixed("Frequency", "lr"), nsim=100)
# inspect results
pFrequency
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency. We continue by checking the pwoer of the sample to detect the weakest medium effect for Gender.

```{r ampause_03_97, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m2p <- m2.glmer
fixef(m2p)["GenderWoman"] <- 1.245
pGender <- powerSim(m2p, fixed("Gender", "lr"), nsim=100)
# inspect results
pGender
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Gradability. We continue by checking the pwoer of the sample to detect the weakest medium effect for Age. We start with age group 26-40.

```{r ampause_03_99, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m3p <- m3.glmer
fixef(m3p)["Age26-40"] <- 1.245
pAge2640 <- powerSim(m3p, fixed("Age", "lr"), nsim=100)
# inspect results
pAge2640
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for age group 26-40. 


```{r ampause_03_101, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m3p <- m3.glmer
fixef(m3p)["Age41-80"] <- 1.245
pAge4180 <- powerSim(m3p, fixed("Age", "lr"), nsim=100)
# inspect results
pAge4180
```


The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for age group 41-80. 

We continue by checking the pwoer of the sample to detect the weakest medium effect for ConversationType.

```{r ampause_03_103, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m4p <- m4.glmer
fixef(m4p)["ConversationTypePrimed"] <- 1.245
pConversationType <- powerSim(m4p, fixed("ConversationType", "lr"), nsim=100)
# inspect results
pConversationType
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for ConversationType. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Gender.

```{r ampause_03_105, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m5p <- m5.glmer
fixef(m5p)["Frequency:GenderWoman"] <- 1.245
pFrequencyGender <- powerSim(m5p, fixed("Frequency:Gender", "lr"), nsim=100)
# inspect results
pFrequencyGender
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:Gradability. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Age2640.

```{r ampause_03_107, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m6pa <- m6.glmer
fixef(m6pa)["Frequency:Age26-40"] <- 1.245
pFrequencyAge2640 <- powerSim(m6pa, fixed("Frequency:Age", "lr"), nsim=100)
# inspect results
pFrequencyAge2640
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:Age2640. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Age41-80.

```{r ampause_03_109, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m6pb <- m6.glmer
fixef(m6pb)["Frequency:Age41-80"] <- 1.245
pFrequencyAge4180 <- powerSim(m6pb, fixed("Frequency:Age", "lr"), nsim=100)
# inspect results
pFrequencyAge4180
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:Age4180. We continue by checking the pwoer of the sample to detect the weakest medium effect for Gender:Age.

```{r ampause_03_111, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m7p <- m7.glmer
fixef(m7p)["Frequency:ConversationTypePrimed"] <- 1.245
pFrequencyConversationType <- powerSim(m7p, fixed("Frequency:ConversationType", "lr"), nsim=100)
# inspect results
pFrequencyConversationType
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:ConversationType. We continue by checking the pwoer of the sample to detect the weakest medium effect for Gender:Age.

```{r ampause_03_113, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m8pa <- m8.glmer
fixef(m8pa)["GenderWoman:Age26-40"] <- 1.245
pGenderAge2640 <- powerSim(m8pa, fixed("Gender:Age", "lr"), nsim=100)
# inspect results
pGenderAge2640
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Gender:Age2640. We continue by checking the pwoer of the sample to detect the weakest medium effect for Gender:Age4180.

```{r ampause_03_115, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m8pb <- m8.glmer
fixef(m8pb)["GenderWoman:Age41-80"] <- 1.245
pGenderAge4180 <- powerSim(m8pb, fixed("Gender:Age", "lr"), nsim=100)
# inspect results
pGenderAge4180
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Gender:Gradability. We continue by checking the pwoer of the sample to detect the weakest medium effect for Gradability:ConversationType.

```{r ampause_03_117, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m9p <- m9.glmer
fixef(m9p)["GenderWoman:ConversationTypePrimed"] <- 1.245
pGenderConversationType <- powerSim(m9p, fixed("Gender:ConversationType", "lr"), nsim=100)
# inspect results
pGenderConversationType
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Gender:ConversationType. We continue by checking the pwoer of the sample to detect the weakest medium effect for Age2640:ConversationType.

```{r ampause_03_119, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m10pa <- m10.glmer
fixef(m10pa)["Age26-40:ConversationTypePrimed"] <- 1.245
pAge2640ConversationType <- powerSim(m10pa, fixed("Age:ConversationType", "lr"), nsim=100)
# inspect results
pAge2640ConversationType
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Age2640:ConversationType. We continue by checking the pwoer of the sample to detect the weakest medium effect for Age41-80:ConversationType.

```{r ampause_03_121, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m10pb <- m10.glmer
fixef(m10pb)["Age41-80:ConversationTypePrimed"] <- 1.245
pAge4180ConversationType <- powerSim(m10pb, fixed("Age:ConversationType", "lr"), nsim=100)
# inspect results
pAge4180ConversationType
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Age41-80:ConversationType. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Gender:Age2640.

```{r ampause_03_123, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m11pa <- m11.glmer
fixef(m11pa)["Frequency:GenderWoman:Age26-40"] <- 1.245
pFrequencyGenderAge2640 <- powerSim(m11pa, fixed("Frequency:Gender:Age", "lr"), nsim=100)
# inspect results
pFrequencyGenderAge2640
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:GenderWoman:Age26-40. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Gender:Age41-80.

```{r ampause_03_125, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m11pb <- m11.glmer
fixef(m11pb)["Frequency:GenderWoman:Age41-80"] <- 1.245
pFrequencyGenderAge4180 <- powerSim(m11pb, fixed("Frequency:Gender:Age", "lr"), nsim=100)
# inspect results
pFrequencyGenderAge4180
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:Gender:Age41-80. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Gender:Gradability.

```{r ampause_03_127, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m12p <- m12.glmer
fixef(m12p)["Frequency:GenderWoman:ConversationTypePrimed"] <- 1.245
pFrequencyGenderConversationType <- powerSim(m12p, fixed("Frequency:Gender:ConversationType", "lr"), nsim=100)
# inspect results
pFrequencyGenderConversationType
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:Gender:ConversationType. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Age2640:ConversationType.

```{r ampause_03_129, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m13pa <- m13.glmer
fixef(m13pa)["Frequency:Age26-40:ConversationTypePrimed"] <- 1.245
pFrequencyAge2640ConversationType <- powerSim(m13pa, fixed("Frequency:Age:ConversationType", "lr"), nsim=100)
# inspect results
pFrequencyAge2640ConversationType
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:Age2640:ConversationType. We continue by checking the pwoer of the sample to detect the weakest medium effect for Frequency:Age4180:ConversationType.

```{r ampause_03_131, echo=T, eval = T, message=FALSE, warning=FALSE}
set.seed(202003206)
m13pb <- m13.glmer
fixef(m13pb)["Frequency:Age41-80:ConversationTypePrimed"] <- 1.245
pFrequencyAge4180ConversationType <- powerSim(m13pb, fixed("Frequency:Age:ConversationType", "lr"), nsim=100)
# inspect results
pFrequencyAge4180ConversationType
```

The power analysis shows that the sample size is fully sufficient to detect the weakest medium effect for Frequency:Age4180:ConversationType. We have reached the end of part 3 of the analysis.
